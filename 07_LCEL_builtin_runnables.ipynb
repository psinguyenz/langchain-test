{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bed34322",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37221380",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4.1-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e3e472",
   "metadata": {},
   "source": [
    "# RunnablePassthrough\n",
    "- It does not do anything to the input data.\n",
    "- Let's see it in a very simple example: a chain with just RunnablePassthrough() will output the original input without any modification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04138277",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain = RunnablePassthrough()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd30d289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SiZ'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"SiZ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd57094b",
   "metadata": {},
   "source": [
    "# RunnableLambda\n",
    "- To use a custom function inside a LCEL chain we need to wrap it up with RunnableLambda.\n",
    "- Let's define a very simple function to create Russian lastnames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "526a3b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def russian_lastname(name: str) -> str:\n",
    "    return f\"{name}ovich\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4945cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "chain = RunnablePassthrough() | RunnableLambda(russian_lastname)\n",
    "# chain = RunnableLambda(russian_lastname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac70d9ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SiZovich'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"SiZ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bff54d2",
   "metadata": {},
   "source": [
    "# RunnableParallel\n",
    "- We will use RunnableParallel() for running tasks in parallel.\n",
    "- This is probably the most important and most useful Runnable from LangChain.\n",
    "- In the following chain, RunnableParallel is going to run these two tasks in parallel:\n",
    "    + operation_a will use RunnablePassthrough.\n",
    "    + operation_b will use RunnableLambda with the russian_lastname function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52ca3267",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "chain = RunnableParallel(\n",
    "    {\n",
    "        \"operation_a\": RunnablePassthrough(),\n",
    "        \"operation_b\": RunnableLambda(russian_lastname)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b33046a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'operation_a': 'SiZ', 'operation_b': 'SiZovich'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"SiZ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98a2e822",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "80e22044",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"tell me a curious fact about {soccer_player}\")\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3919f398",
   "metadata": {},
   "outputs": [],
   "source": [
    "def russian_lastname_from_dictionary(person):\n",
    "    return person[\"name\"] + \"ovich\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "929dca6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RunnableParallel(\n",
    "    {\n",
    "        \"operation_a\": RunnablePassthrough(),\n",
    "        \"soccer_player\": RunnableLambda(russian_lastname_from_dictionary),\n",
    "        \"operation_c\": RunnablePassthrough(),\n",
    "    }\n",
    ") | prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13e57af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A curious fact about Roman Abramovich is that before he became a billionaire businessman and owner of Chelsea Football Club, he started out with very modest beginnings in post-Soviet Russia. After the collapse of the Soviet Union, Abramovich capitalized on the new opportunities during Russia’s privatization era, acquiring stakes in oil companies. One notable—and somewhat ironic—story is that he reportedly bought the oil company Sibneft at a fraction of its value during a controversial privatization auction, which later made him one of the richest men in Russia. This rapid rise from a relatively modest background to immense wealth is often cited as emblematic of the chaotic economic changes in Russia during the 1990s.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\n",
    "    \"name1\": \"Jordam\", # Name1 not given\n",
    "    \"name\": \"Abram\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff74926",
   "metadata": {},
   "source": [
    "Advanced RunnableParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4b661f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SiZ is a content creator who primarily focuses on game-related content, including highlights, strategies, and tips for players.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "vectorstore = FAISS.from_texts(\n",
    "    [\"SiZ primarily focused contents on game, highlights, strategies, and tips for players.\"], \n",
    "    embedding=OpenAIEmbeddings()\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
    "\n",
    "retrieval_chain = (\n",
    "    RunnableParallel({\"context\": retriever, \"question\": RunnablePassthrough()}) # passing both\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "retrieval_chain.invoke(\"What is SiZ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e2da4ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Arrr, SiZ be a treasure trove o' game contents, sharin' highlights, strategies, and tips fer all ye players sailin' the digital seas!\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
    "\n",
    "vectorstore = FAISS.from_texts(\n",
    "    [\"SiZ primarily focused contents on game, highlights, strategies, and tips for players.\"], \n",
    "    embedding=OpenAIEmbeddings()\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer in the following language: {language}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": itemgetter(\"question\") | retriever,\n",
    "        \"question\": itemgetter(\"question\"),\n",
    "        \"language\": itemgetter(\"language\"),\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain.invoke({\"question\": \"What is SiZ?\", \"language\": \"Pirate English\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmapp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
